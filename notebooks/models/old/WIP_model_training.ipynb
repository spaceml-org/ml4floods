{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adolescent-feeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3efepcvg) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11484<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sambudd/ml4floods/notebooks/models/wandb/run-20210218_163716-3efepcvg/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sambudd/ml4floods/notebooks/models/wandb/run-20210218_163716-3efepcvg/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>bce_loss</td><td>0.16456</td></tr><tr><td>dice_loss</td><td>0.5807</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>_runtime</td><td>6945</td></tr><tr><td>_timestamp</td><td>1613673187</td></tr><tr><td>_step</td><td>19</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>bce_loss</td><td>▁▇█▆▄▁▁▁▁▁</td></tr><tr><td>dice_loss</td><td>█▅▁▂▆▅▅▅▅▄</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stellar-cloud-4</strong>: <a href=\"https://wandb.ai/sambuddinc/ml4floods-test/runs/3efepcvg\" target=\"_blank\">https://wandb.ai/sambuddinc/ml4floods-test/runs/3efepcvg</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3efepcvg). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.19<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">young-meadow-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sambuddinc/ml4floods-test\" target=\"_blank\">https://wandb.ai/sambuddinc/ml4floods-test</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sambuddinc/ml4floods-test/runs/15uhl99p\" target=\"_blank\">https://wandb.ai/sambuddinc/ml4floods-test/runs/15uhl99p</a><br/>\n",
       "                Run data is saved locally in <code>/home/sambudd/ml4floods/notebooks/models/wandb/run-20210218_183307-15uhl99p</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(15uhl99p)</h1><iframe src=\"https://wandb.ai/sambuddinc/ml4floods-test/runs/15uhl99p\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f244f633090>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio import plot as rasterioplt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from src.models.modelmodule import WorldFloodsModel\n",
    "from src.models.architectures.unets import UNet\n",
    "from src.models.utils import model_setup, metrics\n",
    "from src.models.utils.configuration import AttrDict\n",
    "\n",
    "\n",
    "# Init wandb\n",
    "import wandb\n",
    "wandb.init(project=\"ml4floods-test\", entity=\"sambuddinc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "piano-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def read_inference_pair(layer_name:str, window:Optional[Union[rasterio.windows.Window, Tuple[slice,slice]]], \n",
    "                        return_ground_truth: bool=False, channels:bool=None, \n",
    "                        return_permanent_water=True) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, rasterio.Affine]:\n",
    "    \"\"\"\n",
    "    Read a pair of layers from the worldfloods bucket and return them as Tensors to pass to a model, return the transform for plotting with lat/long\n",
    "    \n",
    "    Args:\n",
    "        layer_name: filename for layer in worldfloods bucket\n",
    "        window: window of layer to use\n",
    "        return_ground_truth: flag to indicate if paired gt layer should be returned\n",
    "        channels: list of channels to read from the image\n",
    "        return_permanent_water: Read permanent water layer raster\n",
    "    \n",
    "    Returns:\n",
    "        (torch_inputs, torch_targets, transform): inputs Tensor, gt Tensor, transform for plotting with lat/long\n",
    "    \"\"\"\n",
    "    tiff_inputs = f\"gs://ml4floods/worldfloods/tiffimages/S2/{layer_name}.tif\"\n",
    "    tiff_targets = f\"gs://ml4floods/worldfloods/tiffimages/gt/{layer_name}.tif\"\n",
    "\n",
    "    with rasterio.open(tiff_inputs, \"r\") as rst:\n",
    "        inputs = rst.read((np.array(channels) + 1).tolist(), window=window)\n",
    "        # Shifted transform based on the given window (used for plotting)\n",
    "        transform = rst.transform if window is None else rasterio.windows.transform(window, rst.transform)\n",
    "        torch_inputs = torch.Tensor(inputs.astype(np.float32)).unsqueeze(0)\n",
    "    \n",
    "    if return_permanent_water:\n",
    "        tiff_permanent_water = f\"gs://ml4floods/worldfloods/tiffimages/PERMANENTWATERJRC/{layer_name}.tif\"\n",
    "        with rasterio.open(tiff_permanent_water, \"r\") as rst:\n",
    "            permanent_water = rst.read(1, window=window)  \n",
    "            torch_permanent_water = torch.tensor(permanent_water)\n",
    "    else:\n",
    "        torch_permanent_water = torch.zeros_like(torch_inputs)\n",
    "        \n",
    "    if return_ground_truth:\n",
    "        with rasterio.open(tiff_targets, \"r\") as rst:\n",
    "            targets = rst.read(1, window=window)\n",
    "        \n",
    "        torch_targets = torch.tensor(targets).unsqueeze(0)\n",
    "    else:\n",
    "        torch_targets = torch.zeros_like(torch_inputs)\n",
    "    \n",
    "    return torch_inputs, torch_targets, torch_permanent_water, transform\n",
    "\n",
    "\n",
    "class DummyWorldFloodsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, layer_names, windows, channels):\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        self.permanent_water = []\n",
    "        self.plot_transforms = []\n",
    "        \n",
    "        for i in range(len(layer_names)):\n",
    "            torch_inputs, torch_targets, torch_permanent_water, transform = read_inference_pair(layer_names[i], windows[i], return_ground_truth=True, channels=channels[i])\n",
    "            \n",
    "            self.inputs.append(torch_inputs)\n",
    "            self.targets.append(torch_targets)\n",
    "            self.permanent_water.append(torch_permanent_water)\n",
    "            self.plot_transforms.append(transform)\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        this_dict = {\n",
    "            'input': self.inputs[idx],\n",
    "            'target': self.targets[idx],\n",
    "            'permanent_water': self.permanent_water[idx],\n",
    "            'plot_transforms': self.plot_transforms[idx]\n",
    "        }\n",
    "        return self.inputs[idx].squeeze(), self.targets[idx].squeeze().long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "described-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some options\n",
    "model_name = 'linear' # options: 'unet', 'linear', 'simplecnn'\n",
    "channel_configuration_name = 'all'\n",
    "\n",
    "opt = {\n",
    "    'model': model_name,\n",
    "    'device': 'cpu',\n",
    "    'model_folder': f'../../src/models/checkpoints/{model_name}/', # TODO different channel configuration means different model\n",
    "    'max_tile_size': 128,\n",
    "    'num_class': 3,\n",
    "    'channel_configuration' : channel_configuration_name,\n",
    "    'num_channels': len(model_setup.CHANNELS_CONFIGURATIONS[channel_configuration_name]),\n",
    "}\n",
    "opt = AttrDict.from_nested_dicts(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stock-mozambique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "layer_names = [\"EMSR333_02PORTOPALO_DEL_MONIT01_v1_observed_event_a\", \"EMSR347_07ZOMBA_DEL_v2_observed_event_a\"]\n",
    "windows = [(slice(256,256+256),slice(0,256)), (slice(256,256+256),slice(0,256))]\n",
    "channels = [model_setup.CHANNELS_CONFIGURATIONS[opt.channel_configuration], model_setup.CHANNELS_CONFIGURATIONS[opt.channel_configuration]]\n",
    "\n",
    "ds = DummyWorldFloodsDataset(layer_names, windows, channels)\n",
    "\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ranging-basket",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name    | Type | Params\n",
      "---------------------------------\n",
      "0 | network | UNet | 7.8 M \n",
      "---------------------------------\n",
      "7.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.8 M     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 2/4 [00:15<00:15,  7.62s/it, loss=1.31, v_num=l99p]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 4/4 [00:17<00:00,  4.50s/it, loss=1.31, v_num=l99p]\n",
      "Epoch 0: 100%|██████████| 4/4 [00:20<00:00,  5.24s/it, loss=1.31, v_num=l99p]\n",
      "Epoch 1:  50%|█████     | 2/4 [00:14<00:14,  7.16s/it, loss=1.21, v_num=l99p]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 4/4 [00:17<00:00,  4.29s/it, loss=1.21, v_num=l99p]\n",
      "Epoch 1: 100%|██████████| 4/4 [00:20<00:00,  5.03s/it, loss=1.21, v_num=l99p]\n",
      "Epoch 2:  50%|█████     | 2/4 [00:14<00:14,  7.18s/it, loss=1.14, v_num=l99p]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 4/4 [00:17<00:00,  4.29s/it, loss=1.14, v_num=l99p]\n",
      "Epoch 2: 100%|██████████| 4/4 [00:20<00:00,  5.02s/it, loss=1.14, v_num=l99p]\n",
      "Epoch 3:  50%|█████     | 2/4 [00:14<00:14,  7.14s/it, loss=0.95, v_num=l99p]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 4/4 [00:17<00:00,  4.25s/it, loss=0.95, v_num=l99p]\n",
      "Epoch 3: 100%|██████████| 4/4 [00:19<00:00,  4.98s/it, loss=0.95, v_num=l99p]\n",
      "Epoch 4:  50%|█████     | 2/4 [00:14<00:14,  7.19s/it, loss=0.855, v_num=l99p]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 4/4 [00:17<00:00,  4.31s/it, loss=0.855, v_num=l99p]\n",
      "Epoch 4: 100%|██████████| 4/4 [00:20<00:00,  5.04s/it, loss=0.855, v_num=l99p]\n",
      "Epoch 5:  50%|█████     | 2/4 [00:15<00:15,  7.86s/it, loss=0.777, v_num=l99p]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 4/4 [00:21<00:00,  5.31s/it, loss=0.777, v_num=l99p]\n",
      "Epoch 5: 100%|██████████| 4/4 [00:27<00:00,  6.80s/it, loss=0.777, v_num=l99p]\n",
      "Epoch 6:  50%|█████     | 2/4 [00:29<00:29, 14.88s/it, loss=0.725, v_num=l99p]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 4/4 [00:35<00:00,  8.83s/it, loss=0.725, v_num=l99p]\n",
      "Epoch 6: 100%|██████████| 4/4 [00:41<00:00, 10.32s/it, loss=0.725, v_num=l99p]\n",
      "Epoch 7:  50%|█████     | 2/4 [00:28<00:28, 14.23s/it, loss=0.683, v_num=l99p]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 4/4 [00:34<00:00,  8.51s/it, loss=0.683, v_num=l99p]\n",
      "Epoch 7: 100%|██████████| 4/4 [00:40<00:00, 10.01s/it, loss=0.683, v_num=l99p]\n",
      "Epoch 8:  50%|█████     | 2/4 [00:29<00:29, 14.75s/it, loss=0.649, v_num=l99p]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  75%|███████▌  | 3/4 [00:36<00:12, 12.09s/it, loss=0.649, v_num=l99p]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = WorldFloodsModel(network_architecture=UNet(opt.num_channels, opt.num_class), num_class=opt.num_class, weight_per_class=[0.120252 + 0.396639, 0.027322, .455787])\n",
    "\n",
    "wandb_logger = WandbLogger(name=f\"floodbusters-test\")\n",
    "\n",
    "trainer = pl.Trainer(logger=wandb_logger, max_epochs=10)\n",
    "trainer.fit(model, dl, dl)\n",
    "\n",
    "# Save model to wandb\n",
    "torch.save(model.state_dict(), os.path.join(wandb.run.dir, 'model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-cornell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-smooth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-steering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coastal-fortune",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acknowledged-modeling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "decimal-humidity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arctic-spyware",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-pencil",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:floodbusters]",
   "language": "python",
   "name": "conda-env-floodbusters-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
