{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "worth-timer",
   "metadata": {},
   "source": [
    "# Notebook to train world floods model\n",
    "    steps:\n",
    "        1. Create dataloader and transforms\n",
    "        2. Create model and pytorch lightening trainer\n",
    "        3. Set up logging\n",
    "        4. Save model to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "central-violence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "from pyprojroot import here\n",
    "# spyder up to find the root\n",
    "root = here(project_files=[\".here\"])\n",
    "# append to path\n",
    "sys.path.append(str(here()))\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/opt/creds/ML4CC_creds.json\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-qualification",
   "metadata": {},
   "source": [
    "### Step 1: Setup Configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adolescent-employment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Config for experiment:  worldfloods_demo_test\n",
      "{   'data_params': {   'bands': 'all',\n",
      "                       'batch_size': 32,\n",
      "                       'bucket_id': 'ml4floods',\n",
      "                       'image_count': 3,\n",
      "                       'input_folder': 'S2',\n",
      "                       'loader_type': 'local',\n",
      "                       'path_to_splits': '/worldfloods/public',\n",
      "                       'target_folder': 'gt',\n",
      "                       'test_transformation': {   'normalize': True,\n",
      "                                                  'num_classes': 3,\n",
      "                                                  'totensor': True,\n",
      "                                                  'use_channels': 'all'},\n",
      "                       'train_transformation': {   'normalize': True,\n",
      "                                                   'num_classes': 3,\n",
      "                                                   'totensor': True,\n",
      "                                                   'use_channels': 'all'},\n",
      "                       'window_size': [256, 256]},\n",
      "    'deploy': False,\n",
      "    'experiment_name': 'worldfloods_demo_test',\n",
      "    'gpus': '0',\n",
      "    'model_params': {   'device': 'cpu',\n",
      "                        'hyperparameters': {   'channel_configuration': 'all',\n",
      "                                               'label_names': [   'land',\n",
      "                                                                  'water',\n",
      "                                                                  'cloud'],\n",
      "                                               'lr': 0.0001,\n",
      "                                               'lr_decay': 0.5,\n",
      "                                               'lr_patience': 2,\n",
      "                                               'max_epochs': 10,\n",
      "                                               'max_tile_size': 256,\n",
      "                                               'model_type': 'linear',\n",
      "                                               'num_channels': 13,\n",
      "                                               'num_classes': 3,\n",
      "                                               'val_every': 1,\n",
      "                                               'weight_per_class': [   0.516942,\n",
      "                                                                       0.027322,\n",
      "                                                                       0.455787]},\n",
      "                        'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
      "                        'path_to_weights': 'checkpoints/',\n",
      "                        'test': True,\n",
      "                        'train': True,\n",
      "                        'use_pretrained_weights': False},\n",
      "    'seed': 12,\n",
      "    'test': False,\n",
      "    'train': False}\n"
     ]
    }
   ],
   "source": [
    "from src.models.config_setup import get_default_config\n",
    "config_fp = os.path.join(root, 'src', 'models', 'configurations', 'worldfloods_template.json')\n",
    "config = get_default_config(config_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "extended-election",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "# Seed\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-curtis",
   "metadata": {},
   "source": [
    "### Step 1.b: Make it a unique experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "retained-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.experiment_name = 'worldfloods-notebook-training-demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-envelope",
   "metadata": {},
   "source": [
    "### Step 2: Setup Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "saved-stamp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local dataset for this run\n",
      "Folder '/worldfloods/public/train/S2' Is Already There.\n",
      "Folder '/worldfloods/public/train/gt' Is Already There.\n",
      "Folder '/worldfloods/public/val/S2' Is Already There.\n",
      "Folder '/worldfloods/public/val/gt' Is Already There.\n",
      "Folder '/worldfloods/public/test/S2' Is Already There.\n",
      "Folder '/worldfloods/public/test/gt' Is Already There.\n",
      "train 196648  tiles\n",
      "val 1284  tiles\n",
      "test 11  tiles\n"
     ]
    }
   ],
   "source": [
    "from src.models.dataset_setup import get_dataset\n",
    "\n",
    "config.data_params.loader_type = 'local'\n",
    "dataset = get_dataset(config.data_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-pattern",
   "metadata": {},
   "source": [
    "### Step 3: Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "appropriate-indian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 3\n"
     ]
    }
   ],
   "source": [
    "from src.models.model_setup import get_model\n",
    "config.model_params.test = False\n",
    "config.model_params.train = True\n",
    "model = get_model(config.model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-physics",
   "metadata": {},
   "source": [
    "### Step 4: WandB Logger (Replace with your wandb info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "southwest-arbor",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3790ncc1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7002<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sambudd/ml4floods/notebooks/models/wandb/run-20210303_173245-3790ncc1/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sambudd/ml4floods/notebooks/models/wandb/run-20210303_173245-3790ncc1/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">clean-bush-1</strong>: <a href=\"https://wandb.ai/sambuddinc/ml4floods-notebooks_models/runs/3790ncc1\" target=\"_blank\">https://wandb.ai/sambuddinc/ml4floods-notebooks_models/runs/3790ncc1</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3790ncc1). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">flowing-universe-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sambuddinc/ml4floods-notebooks_models\" target=\"_blank\">https://wandb.ai/sambuddinc/ml4floods-notebooks_models</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sambuddinc/ml4floods-notebooks_models/runs/1ft53p2p\" target=\"_blank\">https://wandb.ai/sambuddinc/ml4floods-notebooks_models/runs/1ft53p2p</a><br/>\n",
       "                Run data is saved locally in <code>/home/sambudd/ml4floods/notebooks/models/wandb/run-20210303_174704-1ft53p2p</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(1ft53p2p)</h1><iframe src=\"https://wandb.ai/sambuddinc/ml4floods-notebooks_models/runs/1ft53p2p\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7efdb01ece80>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "stuffed-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "config['wandb_entity'] = 'sambuddinc'\n",
    "config['wandb_project'] = 'worldfloods-notebook-demo'\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    name=config.experiment_name,\n",
    "    project=config.wandb_project, \n",
    "    entity=config.wandb_entity\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-lafayette",
   "metadata": {},
   "source": [
    "### Step 5: Setup Lightning Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "supposed-sending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart/worldfloods-notebook-training-demo\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "experiment_path = f\"{config.model_params.model_folder}/{config.experiment_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{experiment_path}/checkpoint\",\n",
    "    save_top_k=True,\n",
    "    verbose=True,\n",
    "    monitor='dice_loss',\n",
    "    mode='min',\n",
    "    prefix=''\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='dice_loss',\n",
    "    patience=10,\n",
    "    strict=False,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stop_callback]\n",
    "\n",
    "print(f\"{config.model_params.model_folder}/{config.experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-american",
   "metadata": {},
   "source": [
    "### Step 6: Setup Lighting Trainer\n",
    "    -- add flags from \n",
    "    https://pytorch-lightning.readthedocs.io/en/0.7.5/trainer.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "featured-privilege",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "config.gpus = '1'\n",
    "\n",
    "trainer = Trainer(\n",
    "    fast_dev_run=False,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    "    default_root_dir=f\"{config.model_params.model_folder}/{config.experiment_name}\",\n",
    "    accumulate_grad_batches=1,\n",
    "    gradient_clip_val=0.0,\n",
    "    auto_lr_find=False,\n",
    "    benchmark=False,\n",
    "    distributed_backend=None,\n",
    "    gpus=config.gpus,\n",
    "    max_epochs=config.model_params.hyperparameters.max_epochs,\n",
    "    check_val_every_n_epoch=config.model_params.hyperparameters.val_every,\n",
    "    log_gpu_memory=None,\n",
    "    resume_from_checkpoint=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "responsible-shark",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type         | Params\n",
      "-----------------------------------------\n",
      "0 | network | SimpleLinear | 42    \n",
      "-----------------------------------------\n",
      "42        Trainable params\n",
      "0         Non-trainable params\n",
      "42        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/6187 [00:00<?, ?it/s]                     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml4floods/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  13%|█▎        | 779/6187 [20:34<2:22:49,  1.58s/it, loss=0.562, v_num=3p2p]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml4floods/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0, global step 778: dice_loss reached 0.85572 (best 0.85572), saving model to \"gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart/worldfloods-notebook-training-demo/checkpoint/epoch=0-step=778.ckpt\" as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  13%|█▎        | 779/6187 [20:35<2:22:56,  1.59s/it, loss=0.562, v_num=3p2p]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-chorus",
   "metadata": {},
   "source": [
    "### Step 7: Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities.cloud_io import atomic_save\n",
    "atomic_save(model.state_dict(), f\"{experiment_path}/model.pt\")\n",
    "torch.save(model.state_dict(), os.path.join(wandb_logger.save_dir, 'model.pt'))\n",
    "wandb.save(os.path.join(wandb_logger.save_dir, 'model.pt'))\n",
    "wandb.finish()\n",
    "\n",
    "# Save cofig file in experiment_path\n",
    "config_file_path = f\"{experiment_path}/config.json\"\n",
    "\n",
    "if config_file_path.startswith(\"gs://\"):\n",
    "    from google.cloud import storage\n",
    "    splitted_path = config_file_path.replace(\"gs://\", \"\").split(\"/\")\n",
    "    bucket_name = splitted_path[0]\n",
    "    blob_name = \"/\".join(splitted_path[1:])\n",
    "    bucket = storage.Client().get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.upload_from_string(\n",
    "        data=json.dumps(config),\n",
    "        content_type='application/json'\n",
    "    )\n",
    "else:\n",
    "    with open(config_file_path, \"w\") as fh:\n",
    "        json.dump(config, fh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml4floods]",
   "language": "python",
   "name": "conda-env-ml4floods-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
