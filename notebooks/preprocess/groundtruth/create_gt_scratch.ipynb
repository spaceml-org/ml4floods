{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "clean-syndicate",
   "metadata": {},
   "source": [
    "# Demo - Generating Groundtruth from S2 images and FloodMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fifteen-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pyprojroot import here\n",
    "\n",
    "# spyder up to find the root\n",
    "root = here(project_files=[\".here\"])\n",
    "\n",
    "# append to path\n",
    "sys.path.append(str(here()))\n",
    "\n",
    "import logging\n",
    "import json\n",
    "from src.data.create_gt import (\n",
    "    generate_water_cloud_binary_gt,\n",
    "    generate_land_water_cloud_gt,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rasterio import features\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from shapely.ops import cascaded_union\n",
    "from src.data.utils import filter_pols, filter_land\n",
    "from typing import Optional, Dict, Tuple\n",
    "from src.data.config import BANDS_S2, CODES_FLOODMAP, UNOSAT_CLASS_TO_TXT\n",
    "\n",
    "from google.cloud import storage\n",
    "import json\n",
    "import rasterio.windows\n",
    "\n",
    "\n",
    "from rasterio.plot import show as rasterio_plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-going",
   "metadata": {},
   "source": [
    "## PseudoCode\n",
    "\n",
    "1. Get the Name of the Files in Directory\n",
    "2. Loop through the files\n",
    "    * Get the S2 Image\n",
    "    * Get the floodmap\n",
    "    * Get the metadata\n",
    "3. Generate the FloodMap\n",
    "    * WorldFloods 1.1 - 3-class\n",
    "    * WorldFloods 2.0 - dual channel, binary (cloud, water)\n",
    "4. Save them in the bucket\n",
    "    * declare ML stuffs (train,test,val)\n",
    "    * save the S2 Image\n",
    "    * save the groundtruth mask\n",
    "    * save the floodmap\n",
    "    * save the meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-mainstream",
   "metadata": {},
   "source": [
    "## 1 - Get the Name of the Files in Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "annoying-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.utils import get_files_in_bucket_directory, add_gcp_prefix, parse_gcp_path, copy_file_between_gcpbuckets\n",
    "from collections import namedtuple\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subsequent-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_loop = namedtuple(\"path_loop\", [\"bucket_id\", \"parent_path\", \"ml_path\", \"file_type\"])\n",
    "\n",
    "\n",
    "def create_full_parent_path(path_loop, gcp_prefix: bool=False):\n",
    "    \n",
    "    full_path = Path(path_loop.parent_path).joinpath(path_loop.ml_path).joinpath(path_loop.file_type)\n",
    "    \n",
    "    if gcp_prefix:\n",
    "        full_path = add_gcp_prefix(full_path, path_loop.bucket_id)\n",
    "    \n",
    "    return str(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "composite-ethnic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml4floods/worldfloods/public/test/S2\n"
     ]
    }
   ],
   "source": [
    "ml_paths = [\"test\", \"train\", \"val\"]\n",
    "\n",
    "demo_path = path_loop(\"ml4floods\", \"worldfloods/public\", \"test\", \"S2\")\n",
    "\n",
    "full_parent_path = create_full_parent_path(demo_path, True)\n",
    "print(full_parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "satisfactory-assets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['worldfloods/public/test/S2/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.tif',\n",
      " 'worldfloods/public/test/S2/EMSR286_09ITUANGOSOUTH_DEL_MONIT02_v1_observed_event_a.tif',\n",
      " 'worldfloods/public/test/S2/EMSR333_01RATTALORO_DEL_MONIT01_v1_observed_event_a.tif',\n",
      " 'worldfloods/public/test/S2/EMSR333_02PORTOPALO_DEL_MONIT01_v1_observed_event_a.tif',\n",
      " 'worldfloods/public/test/S2/EMSR333_13TORRECOLONNASPERONE_DEL_MONIT01_v2_observed_event_a.tif',\n",
      " 'worldfloods/public/test/S2/EMSR342_06NORTHNORMANTON_DEL_v1_observed_event_a.tif',\n",
      " 'worldfloods/public/test/S2/EMSR342_07SOUTHNORMANTON_DEL_MONIT03_v2_observed_event_a.tif',\n",
      " 'worldfloods/public/test/S2/EMSR347_06MWANZA_DEL_v1_observed_event_a.tif',\n",
      " 'worldfloods/public/test/S2/EMSR347_07ZOMBA_DEL_MONIT01_v1_observed_event_a.tif',\n",
      " 'worldfloods/public/test/S2/EMSR347_07ZOMBA_DEL_v2_observed_event_a.tif',\n",
      " 'worldfloods/public/test/S2/EMSR9284_01YLITORNIONORTHERN_DEL_MONIT01_v1_observed_event_a.tif']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "files_in_bucket = get_files_in_bucket_directory(\"ml4floods\", directory=\"worldfloods/public/test/S2\", suffix=\".tif\")\n",
    "\n",
    "pprint(files_in_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-content",
   "metadata": {},
   "source": [
    "# 0.1 - Plumbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dress-diving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml4floods/worldfloods/public/test/S2/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.tif\n",
      "gs://ml4floods/worldfloods/public/test/floodmaps/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.shp\n",
      "gs://ml4floods/worldfloods/public/test/meta/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.json\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://ml4floods/worldfloods/public/test/S2/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.tif\n",
    "!gsutil ls gs://ml4floods/worldfloods/public/test/floodmaps/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.shp\n",
    "!gsutil ls gs://ml4floods/worldfloods/public/test/meta/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataclasses import dataclass, field\n",
    "\n",
    "# def parse_gcp_path(full_path) -> Tuple[str]:\n",
    "#     \"\"\"Parse the bucket\"\"\"\n",
    "#     # parse the components\n",
    "#     bucket_id = str(Path(full_path.split(\"gs://\")[1]).parts[0])\n",
    "#     file_path = str(Path(full_path.split(bucket_id)[1]).parent)\n",
    "#     file_name = str(Path(full_path).name)\n",
    "#     return bucket_id, file_path, file_name\n",
    "\n",
    "# @dataclass\n",
    "# class GCPPath:\n",
    "#     full_path: str\n",
    "#     bucket_id : str = field(default=None)\n",
    "#     parent_path : str = field(default=None)\n",
    "#     file_name : str = field(default=None)\n",
    "#     suffix : str = field(default=None)\n",
    "    \n",
    "        \n",
    "#     def __init__(self, full_path):\n",
    "        \n",
    "        \n",
    "#         self.full_path = full_path\n",
    "# #         print(self.full_path)\n",
    "#         self.bucket_id = str(Path(full_path.split(\"gs://\")[1]).parts[0])\n",
    "        \n",
    "# #         print(self.bucket_id)\n",
    "#         self.parent_path = str(Path(full_path.split(self.bucket_id)[1]).parent)[1:]\n",
    "# #         print(self.parent_path)\n",
    "#         self.file_name = str(Path(full_path).name)\n",
    "# #         print(self.file_name)\n",
    "#         self.suffix = self.file_name.split(\".\")[1]\n",
    "# #         print(self.suffix)\n",
    "        \n",
    "\n",
    "        \n",
    "#     def get_files_in_parent_directory(self,**kwargs):\n",
    "#         # initialize client\n",
    "#         client = storage.Client(**kwargs)\n",
    "#         # get bucket\n",
    "#         bucket = client.get_bucket(self.bucket_id)\n",
    "#         # get blob\n",
    "        \n",
    "#         blobs = bucket.list_blobs(prefix=self.parent_path)\n",
    "#         # check if it exists\n",
    "        \n",
    "#         files = [\"gs://\" + str(Path(self.bucket_id).joinpath(x.name)) for x in blobs ]\n",
    "#         return files\n",
    "#     def get_files_in_parent_directory_with_suffix(self, suffix=str, **kwargs):\n",
    "#         # initialize client\n",
    "#         client = storage.Client(**kwargs)\n",
    "#         # get bucket\n",
    "#         bucket = client.get_bucket(self.bucket_id)\n",
    "#         # get blob\n",
    "        \n",
    "#         blobs = bucket.list_blobs(prefix=self.parent_path)\n",
    "#         # check if it exists\n",
    "#         files = [\"gs://\" + str(Path(self.bucket_id).joinpath(x.name)) for x in blobs if str(Path(x.name).suffix) == suffix]\n",
    "#         return files\n",
    "     \n",
    "#     def transfer_file_to_bucket(self, destination_bucket_name: str, destination_file_path: str, **kwargs):\n",
    "        \n",
    "        \n",
    "#         storage_client = storage.Client(**kwargs)\n",
    "#         source_bucket = storage_client.get_bucket(self.bucket_id)\n",
    "#         source_blob = source_bucket.blob(self.get_file_path())\n",
    "        \n",
    "#         destination_bucket = storage_client.get_bucket(destination_bucket_name)\n",
    "        \n",
    "#         destination_blob_name = str(Path(destination_file_path).joinpath(self.file_name))\n",
    "#         # copy to new destination\n",
    "#         new_blob = source_bucket.copy_blob(\n",
    "#             source_blob, destination_bucket, destination_blob_name\n",
    "#         )\n",
    "\n",
    "        \n",
    "#         return self\n",
    "        \n",
    "    \n",
    "# #         return get_files_in_bucket_directory(self.bucket_id, directory=self.parent_path, suffix=self.suffix)\n",
    "    \n",
    "#     def get_file_path(self):\n",
    "#         return str(Path(self.parent_path).joinpath(self.file_name))\n",
    "    \n",
    "#     def replace_bucket(self, bucket_id):\n",
    "#         self.bucket_id = bucket_id\n",
    "#         return self\n",
    "    \n",
    "#     def replace_file_name(self, file_name):\n",
    "#         self.file_name = file_name\n",
    "#         return self\n",
    "    \n",
    "#     def replace(self, original: str, replacement: str):\n",
    "        \n",
    "#         full_path =  self.full_path.replace(original, replacement)\n",
    "        \n",
    "# #         self.__init__(full_path)\n",
    "        \n",
    "#         return GCPPath(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "legendary-assumption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_to_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "judicial-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Optional, Dict\n",
    "\n",
    "\n",
    "\n",
    "# def save_groundtruth_tiff_rasterio(image_gt: np.ndarray, destination_path: str, gt_meta: Optional[Dict]=None, **kwargs)-> None:\n",
    "#     \"\"\"Save image as tiff with rasterio\n",
    "    \n",
    "#     Args:\n",
    "#         image (np.ndarray): image to be saved\n",
    "#             image should be of size (n_channels, height, width)\n",
    "#         destination_path (str): path where the image is saved\n",
    "#         gt_meta Optional[Dict]: a dictionary of extra metadata to be saved in \n",
    "#             the tags\n",
    "#         **kwargs\n",
    "    \n",
    "#     Examples:\n",
    "#         >>> destination_path = \"./temp.tif\"\n",
    "#         >>> # path to image for coordinates\n",
    "#         >>> with rasterio.open(s2_image_path) as src_s2:\n",
    "#         >>>    crs = src_s2.crs\n",
    "#         >>>    transform = src_s2.transform\n",
    "#         >>> save_groundtruth_tiff_rasterio(\n",
    "#             gt, destination_path,\n",
    "#             transform=transform, crs=crs\n",
    "#         )\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # get image channels\n",
    "#     if image_gt.ndim != 3:\n",
    "#         image_gt = image_gt[None, ...]\n",
    "        \n",
    "#     n_channels, height, width = image_gt.shape\n",
    "    \n",
    "#     print(image_gt.shape)\n",
    "\n",
    "#     # write the image\n",
    "#     with rasterio.open(\n",
    "#                 destination_path, \n",
    "#                 'w', \n",
    "#                 driver='COG', \n",
    "#                 height=height, \n",
    "#                 width=width,\n",
    "#                 count=n_channels,\n",
    "#                 dtype=image_gt.dtype, \n",
    "#                 **kwargs) as dst:\n",
    "        \n",
    "#         if gt_meta is not None:\n",
    "#             dst.update_tags(gt_meta=gt_meta)\n",
    "#         dst.write(image_gt)\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "expensive-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.crs import CRS\n",
    "from affine import Affine\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "immune-boards",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml4floods/worldfloods/public/test/S2/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.tif\n",
      "gs://ml4floods/worldfloods/public/test/floodmaps/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.tif\n",
      "gs://ml4floods/worldfloods/public/test/floodmaps/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.shp\n",
      "gs://ml4floods/worldfloods/public/test/meta/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.tif\n",
      "gs://ml4floods/worldfloods/public/test/meta/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving S2 image...:   0%|          | 0/3 [01:24<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_DEV/2_Mart/worldfloods_v1_1/test/S2/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving meta data...:   0%|          | 0/3 [01:27<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_DEV/2_Mart/worldfloods_v1_1/test/meta/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving meta data...:   0%|          | 0/3 [01:28<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_DEV/2_Mart/worldfloods_v1_1/test/floodmap/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving GT data...:   0%|          | 0/3 [01:28<?, ?it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml4cc_data_lake/worldfloods/public/test/S2/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.tif\n",
      "gs://ml4cc_data_lake/worldfloods/public/test/gt/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.tif\n",
      "gs://ml4cc_data_lake/0_DEV/2_Mart/worldfloods_v1_1/test/gt/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.tif\n",
      "(1, 2643, 2170)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving GT data...:   0%|          | 0/3 [01:29<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from src.data.utils import save_file_to_bucket\n",
    "\n",
    "# looping through the ML parts\n",
    "ml_paths = [\n",
    "    \"test\", \n",
    "#     \"train\", \n",
    "    \"val\"]\n",
    "\n",
    "bucket_id = \"ml4floods\"\n",
    "destination_bucket_id = \"ml4cc_data_lake\"\n",
    "\n",
    "parent_path = \"worldfloods/public\"\n",
    "destination_parent_path = \"0_DEV/2_Mart/worldfloods_v1_1\"\n",
    "temp_file = \"./temp_image.tif\"\n",
    "\n",
    "\n",
    "demo_image = \"gs://ml4floods/worldfloods/public/test/S2/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.tif\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for ipath in ml_paths:\n",
    "    # want the appropate ml path\n",
    "    demo_image_gcp = GCPPath(demo_image)\n",
    "    \n",
    "    # ensure path name is the same as ipath for the loooop\n",
    "    demo_image_gcp = demo_image_gcp.replace(\"test\", ipath)\n",
    "\n",
    "    # get all files in the parent directory\n",
    "    files_in_bucket = demo_image_gcp.get_files_in_parent_directory_with_suffix(\".tif\")\n",
    "\n",
    "    \n",
    "    \n",
    "    # loop through files in the bucket\n",
    "    with tqdm.tqdm(files_in_bucket[:3]) as pbar: \n",
    "        for s2_image_path in pbar:\n",
    "            \n",
    "            \n",
    "            s2_image_path = GCPPath(s2_image_path)\n",
    "\n",
    "            \n",
    "            # create floodmap path\n",
    "            floodmap_path = demo_image_gcp.replace(\"/S2/\", \"/floodmaps/\")\n",
    "            floodmap_path = floodmap_path.replace(\".tif\", \".shp\")\n",
    "            \n",
    "            # create meta path\n",
    "            meta_path = demo_image_gcp.replace(\"/S2/\", \"/meta/\")\n",
    "            meta_path = meta_path.replace(\".tif\", \".json\")\n",
    "            \n",
    "            # ==============================\n",
    "            # Generate GT Image\n",
    "            # ==============================\n",
    "            # generate gt and gt meta\n",
    "            gt, gt_meta = generate_land_water_cloud_gt(s2_image_path.full_path, floodmap_path.full_path, keep_streams=True)\n",
    "            \n",
    "\n",
    "            # ==============================\n",
    "            # SAVE GT Image\n",
    "            # ==============================\n",
    "            pbar.set_description(\"Saving GT data...\")\n",
    "\n",
    "\n",
    "            # replace bucket path\n",
    "\n",
    "            \n",
    "\n",
    "            # get necessary geocoordinates\n",
    "            crs, transform = _get_image_geocoords(s2_image_path.full_path)\n",
    "            \n",
    "            # ==============================\n",
    "            # SAVE S2 Image\n",
    "            # ==============================\n",
    "            pbar.set_description(\"Saving S2 image...\")\n",
    "            # get parent path name\n",
    "            s2_image_parent_destination = Path(destination_parent_path).joinpath(ipath).joinpath(\"S2\")\n",
    "            s2_image_path.transfer_file_to_bucket(destination_bucket_id, s2_image_parent_destination)\n",
    "            \n",
    "            \n",
    "            # ==============================\n",
    "            # SAVE Meta Data\n",
    "            # ==============================\n",
    "            pbar.set_description(\"Saving meta data...\")\n",
    "            # get parent path name\n",
    "            meta_parent_destination = Path(destination_parent_path).joinpath(ipath).joinpath(\"meta\")\n",
    "            meta_path.transfer_file_to_bucket(destination_bucket_id, meta_parent_destination)\n",
    "            \n",
    "            \n",
    "            # ==============================\n",
    "            # SAVE FloodMap Data\n",
    "            # ==============================\n",
    "            pbar.set_description(\"Saving meta data...\")\n",
    "            # get parent path name\n",
    "            floodmap_parent_destination = Path(destination_parent_path).joinpath(ipath).joinpath(\"floodmap\")\n",
    "            floodmap_path.transfer_file_to_bucket(destination_bucket_id, floodmap_parent_destination)\n",
    "            \n",
    "            # ==============================\n",
    "            # SAVE GT Data\n",
    "            # ==============================\n",
    "            pbar.set_description(\"Saving GT data...\")\n",
    "            \n",
    "            # replace parent path\n",
    "            gt_path = demo_image_gcp.replace(bucket_id, destination_bucket_id)\n",
    "            gt_path = gt_path.replace(\"/S2/\", \"/gt/\")\n",
    "            gt_path = gt_path.replace(parent_path, destination_parent_path)\n",
    "\n",
    "\n",
    "            # save ground truth\n",
    "            save_groundtruth_tiff_rasterio(gt, f\"./{gt_path.file_name}\", gt_meta=gt_meta, crs=crs, transform=transform)\n",
    "            save_file_to_bucket(gt_path.full_path, f\"./{gt_path.file_name}\")\n",
    "            Path(f\"./{gt_path.file_name}\").unlink()\n",
    "\n",
    "            break\n",
    "            \n",
    "    break\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "#             # ==============================\n",
    "#             # Generate GT Image\n",
    "#             # ==============================\n",
    "#             # generate gt and gt meta\n",
    "#             gt, gt_meta = generate_land_water_cloud_gt(s2_image_path, floodmap_path, keep_streams=True)\n",
    "            \n",
    "#             # get save path\n",
    "#             gt_path = s2_image_path.replace(\"/S2/\", \"/gt/\").replace(parent_path, destination_parent_path).replace(bucket_id, destination_bucket_id)\n",
    "            \n",
    "#             # get necessary geocoordinates\n",
    "#             crs, transform = _get_image_geocoords(s2_image_path)\n",
    "            \n",
    "            \n",
    "#             # ============================\n",
    "#             # SAVE ALL THE THINGS\n",
    "#             # ============================\n",
    "            \n",
    "#             # S2 Image\n",
    "            \n",
    "#             # 1 - remove gcp path\n",
    "#             s2_image_path_destination = remove_gcp_prefix(s2_image_path, True)\n",
    "#             # 2 - replace parent path\n",
    "#             s2_image_path_destination = s2_image_path_destination.replace(parent_path, destination_parent_path)\n",
    "            \n",
    "#             copy_file_between_gcpbuckets(s2_image_path)\n",
    "\n",
    "            \n",
    "#             # save gt image locally\n",
    "#             save_groundtruth_tiff_rasterio(gt, temp_file, crs=crs, transform=transform)\n",
    "            \n",
    "#             # upload to the bucket\n",
    "#             save_file_to_bucket(gt_path, temp_file)\n",
    "            \n",
    "#             # delete localfile\n",
    "#             Path(temp_file).unlink()\n",
    "            \n",
    "#             # save gt meta\n",
    "# #             save_file(gt, gt_path, crs=crs, transform=transform)\n",
    "            \n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "major-apparel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml4cc_data_lake/worldfloods/public/test/S2/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.tif\n",
      "gs://ml4cc_data_lake/worldfloods/public/test/gt/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.tif\n",
      "gs://ml4cc_data_lake/0_DEV/2_Mart/worldfloods_v1_1/test/gt/EMSR286_08ITUANGONORTH_DEL_MONIT02_v1_observed_event_a.tif\n",
      "(1, 2643, 2170)\n"
     ]
    }
   ],
   "source": [
    "# \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml4fl_py38]",
   "language": "python",
   "name": "conda-env-ml4fl_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
