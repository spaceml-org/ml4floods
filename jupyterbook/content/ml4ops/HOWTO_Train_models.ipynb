{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "short-header",
   "metadata": {},
   "source": [
    "# Train models\n",
    "\n",
    "* **Last Modified**: 07-04-2021\n",
    "* **Authors**: Sam Budd, Gonzalo Mateo-GarcÃ­a\n",
    "---\n",
    "\n",
    "> Tutorial: Train a Flood Extent segmentation model using the WorldFloods[1] dataset\n",
    "\n",
    "[1] Mateo-Garcia, G. et al. Towards global flood mapping onboard low cost satellites with machine learning. _Scientific Reports 11, 7249_ (2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-ethernet",
   "metadata": {},
   "source": [
    "### Step 0: install the `ml4floods` package if not installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "detailed-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/spaceml-org/ml4floods#egg=ml4floods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cubic-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-thursday",
   "metadata": {},
   "source": [
    "### Step 1: Setup Configuration file\n",
    "    - Load configuration file from local device or gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "broken-camera",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Config for experiment:  worldfloods_demo_test\n",
      "{   'data_params': {   'batch_size': 32,\n",
      "                       'bucket_id': 'ml4cc_data_lake',\n",
      "                       'channel_configuration': 'all',\n",
      "                       'filter_windows': {   'apply': False,\n",
      "                                             'threshold_clouds': 0.5,\n",
      "                                             'version': 'v1'},\n",
      "                       'input_folder': 'S2',\n",
      "                       'loader_type': 'local',\n",
      "                       'num_workers': 4,\n",
      "                       'path_to_splits': 'worldfloods',\n",
      "                       'target_folder': 'gt',\n",
      "                       'test_transformation': {'normalize': True},\n",
      "                       'train_test_split_file': '2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json',\n",
      "                       'train_transformation': {'normalize': True},\n",
      "                       'window_size': [256, 256]},\n",
      "    'deploy': False,\n",
      "    'experiment_name': 'worldfloods_demo_test',\n",
      "    'gpus': '0',\n",
      "    'model_params': {   'hyperparameters': {   'channel_configuration': 'all',\n",
      "                                               'label_names': [   'land',\n",
      "                                                                  'water',\n",
      "                                                                  'cloud'],\n",
      "                                               'lr': 0.0001,\n",
      "                                               'lr_decay': 0.5,\n",
      "                                               'lr_patience': 2,\n",
      "                                               'max_epochs': 10,\n",
      "                                               'max_tile_size': 256,\n",
      "                                               'metric_monitor': 'val_dice_loss',\n",
      "                                               'model_type': 'linear',\n",
      "                                               'num_channels': 13,\n",
      "                                               'num_classes': 3,\n",
      "                                               'val_every': 1,\n",
      "                                               'weight_per_class': [   1.93445299,\n",
      "                                                                       36.60054169,\n",
      "                                                                       2.19400729]},\n",
      "                        'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
      "                        'model_version': 'v1',\n",
      "                        'test': True,\n",
      "                        'train': True},\n",
      "    'resume_from_checkpoint': False,\n",
      "    'seed': 12,\n",
      "    'test': False,\n",
      "    'train': False}\n"
     ]
    }
   ],
   "source": [
    "from ml4floods.models.config_setup import get_default_config\n",
    "import pkg_resources\n",
    "\n",
    "# Set filepath to configuration files\n",
    "# config_fp = 'path/to/worldfloods_template.json'\n",
    "config_fp = pkg_resources.resource_filename(\"ml4floods\",\"models/configurations/worldfloods_template.json\")\n",
    "\n",
    "config = get_default_config(config_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-soviet",
   "metadata": {},
   "source": [
    "### Step 1.a: Seed everything for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hidden-stick",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "# Seed\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-arrival",
   "metadata": {},
   "source": [
    "### Step 1.b: Make it a unique experiment\n",
    "    - 'experiment_name' is used to specify the folder in which to save models and associated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "velvet-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.experiment_name = 'training_demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-rabbit",
   "metadata": {},
   "source": [
    "### Step 2: Setup Dataloader\n",
    "    - 'loader_type' can be one of 'local' which assumes the images are already saved locally, or 'bucket' which will load images directly from the bucket specified in 'bucket_id'. To load images from the bucket the `GOOGLE_APPLICATION_CREDENTIALS` env variable must be set. If set to 'local' and the dataset is not found in the path `config.data_params.path_to_splits` it will trigger the download of the data.\n",
    "    - The WorldFloods dataset contains 264.29GB of data. We can load a subset of this by using the train_test_split_sample.json which will only download a subset of the training dataset and the validation and test sets (13GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "offensive-transcription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local dataset for this run\n",
      "Downloading worldfloods_v1_sample/train/S2 if needed\n",
      "Downloading worldfloods_v1_sample/train/gt if needed\n",
      "Downloading worldfloods_v1_sample/test/S2 if needed\n",
      "Downloading worldfloods_v1_sample/test/gt if needed\n",
      "Downloading worldfloods_v1_sample/val/S2 if needed\n",
      "Downloading worldfloods_v1_sample/val/gt if needed\n",
      "train 6298  tiles\n",
      "val 1284  tiles\n",
      "test 11  tiles\n",
      "CPU times: user 5.74 s, sys: 890 ms, total: 6.63 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from ml4floods.models.dataset_setup import get_dataset\n",
    "\n",
    "config.data_params.batch_size = 32 # control this depending on the space on your GPU!\n",
    "config.data_params.loader_type = 'local'\n",
    "config.data_params.path_to_splits = \"worldfloods_v1_sample\" # local folder to download the data\n",
    "config.data_params.train_test_split_file = \"2_PROD/2_Mart/worldfloods_v1_0/train_test_split_sample.json\"\n",
    "\n",
    "config.data_params[\"download\"] = {\"train\": True, \"val\": True, \"test\": False} # download only test data\n",
    "# config.data_params.train_test_split_file = \"2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json\" # use this to train with all the data\n",
    "\n",
    "# If files are not in config.data_params.path_to_splits this will trigger the download of the products.\n",
    "dataset = get_dataset(config.data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prepared-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO Show some images from the dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-bruce",
   "metadata": {},
   "source": [
    "### Step 3: Setup Model\n",
    "     - 'train' = True specifies that we are training a new model from scratch\n",
    "     - get_model(args) constructs a pytorch lightning model using the configuration specified in 'config.model_params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hearing-pavilion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_folder': 'models',\n",
       " 'model_version': 'v1',\n",
       " 'hyperparameters': {'max_tile_size': 256,\n",
       "  'metric_monitor': 'val_dice_loss',\n",
       "  'channel_configuration': 'all',\n",
       "  'label_names': ['land', 'water', 'cloud'],\n",
       "  'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "  'model_type': 'linear',\n",
       "  'num_classes': 3,\n",
       "  'max_epochs': 10,\n",
       "  'val_every': 1,\n",
       "  'lr': 0.0001,\n",
       "  'lr_decay': 0.5,\n",
       "  'lr_patience': 2,\n",
       "  'num_channels': 13},\n",
       " 'train': True,\n",
       " 'test': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # folder to store the trained model (it will create a subfolder with the name of the experiment)\n",
    "config.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "personalized-variation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WorldFloodsModel(\n",
       "  (network): SimpleCNN(\n",
       "    (conv): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(128, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml4floods.models.model_setup import get_model\n",
    "\n",
    "config.model_params.model_folder = \"models\" \n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "config.model_params.test = False\n",
    "config.model_params.train = True\n",
    "config.model_params.hyperparameters.model_type = \"simplecnn\" # Currently implemented: simplecnn, unet, linear\n",
    "model = get_model(config.model_params)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-riverside",
   "metadata": {},
   "source": [
    "### Step 4:  (Optional) Set up Weights and Biases Logger for experiment\n",
    "    - We pass this to the model trainer in a later cell to automaticall log relevant metrics to wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "first-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_weights_and_biases = False\n",
    "if setup_weights_and_biases:\n",
    "    import wandb\n",
    "    from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "    # UNCOMMENT ON FIRST RUN TO LOGIN TO Weights and Biases (only needs to be done once)\n",
    "    # wandb.login()\n",
    "    # run = wandb.init()\n",
    "\n",
    "    # Specifies who is logging the experiment to wandb\n",
    "    config['wandb_entity'] = 'ml4floods'\n",
    "    # Specifies which wandb project to log to, multiple runs can exist in the same project\n",
    "    config['wandb_project'] = 'worldfloods-notebook-demo-project'\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        name=config.experiment_name,\n",
    "        project=config.wandb_project, \n",
    "        entity=config.wandb_entity\n",
    "    )\n",
    "else:\n",
    "    wandb_logger = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-observer",
   "metadata": {},
   "source": [
    "### Step 5: Setup Lightning Callbacks\n",
    "    - We implement checkpointing using the ModelCheckpoint callback to save the best performing checkpoints to local/gcs storage\n",
    "    - We implement early stopping using the EarlyStopping callback to stop training early if there is no performance improvement after 10 epochs from the latest best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "automotive-granny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/training_demo\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "experiment_path = f\"{config.model_params.model_folder}/{config.experiment_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{experiment_path}/checkpoint\",\n",
    "    save_top_k=True,\n",
    "    verbose=True,\n",
    "    monitor='val_dice_loss',\n",
    "    mode='min',\n",
    "    prefix=''\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_dice_loss',\n",
    "    patience=10,\n",
    "    strict=False,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stop_callback]\n",
    "\n",
    "print(f\"The trained model will be stored in {config.model_params.model_folder}/{config.experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-found",
   "metadata": {},
   "source": [
    "### Step 6: Setup Lighting Trainer\n",
    "    -- Pytorch Lightning Trainer handles all the rest of the model training for us!\n",
    "    -- add flags from \n",
    "    https://pytorch-lightning.readthedocs.io/en/0.7.5/trainer.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "european-speaking",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/home/gonzalo/miniconda3/envs/ml4fl_py38/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "config.gpus = '0'  # which gpu to use\n",
    "# config.gpus = None # to not use GPU\n",
    "\n",
    "config.model_params.hyperparameters.max_epochs = 4 # train for maximum 4 epochs\n",
    "\n",
    "trainer = Trainer(\n",
    "    fast_dev_run=False,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    "    default_root_dir=f\"{config.model_params.model_folder}/{config.experiment_name}\",\n",
    "    accumulate_grad_batches=1,\n",
    "    gradient_clip_val=0.0,\n",
    "    auto_lr_find=False,\n",
    "    benchmark=False,\n",
    "    distributed_backend=None,\n",
    "    gpus=config.gpus,\n",
    "    max_epochs=config.model_params.hyperparameters.max_epochs,\n",
    "    check_val_every_n_epoch=config.model_params.hyperparameters.val_every,\n",
    "    log_gpu_memory=None,\n",
    "    resume_from_checkpoint=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-capability",
   "metadata": {},
   "source": [
    "### Start Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fundamental-elite",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type      | Params\n",
      "--------------------------------------\n",
      "0 | network | SimpleCNN | 266 K \n",
      "--------------------------------------\n",
      "266 K     Trainable params\n",
      "0         Non-trainable params\n",
      "266 K     Total params\n",
      "/home/gonzalo/miniconda3/envs/ml4fl_py38/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce232207ff284b03b7f82f3a2847c340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonzalo/miniconda3/envs/ml4fl_py38/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0, global step 13: val_dice_loss reached 0.80061 (best 0.80061), saving model to \"/home/gonzalo/git/ml4floods/jupyterbook/content/ml4ops/models/training_demo/checkpoint/epoch=0-step=13.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-poultry",
   "metadata": {},
   "source": [
    "### Step 7: Eval model in the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from ml4floods.models.utils import metrics\n",
    "from ml4floods.models.model_setup import get_model_inference_function\n",
    "import pandas as pd\n",
    "\n",
    "model.to(\"cuda\")\n",
    "inference_function = get_model_inference_function(model, config, apply_normalization=False, \n",
    "                                                  activation=\"softmax\")\n",
    "\n",
    "dl = dataset.val_dataloader() # pytorch Dataloader\n",
    "\n",
    "# Otherwise fails when reading test dataset from remote bucket\n",
    "# torch.set_num_threads(1)\n",
    "\n",
    "thresholds_water = [0,1e-3,1e-2]+np.arange(0.5,.96,.05).tolist() + [.99,.995,.999]\n",
    "\n",
    "mets = metrics.compute_metrics(\n",
    "    dl,\n",
    "    inference_function, \n",
    "    thresholds_water=thresholds_water, \n",
    "    plot=False)\n",
    "\n",
    "label_names = [\"land\", \"water\", \"cloud\"]\n",
    "metrics.plot_metrics(mets, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-pantyhose",
   "metadata": {},
   "source": [
    "#### Show results for each flood event in the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(dl.dataset, \"image_files\"):\n",
    "    cems_code = [os.path.basename(f).split(\"_\")[0] for f in dl.dataset.image_files]\n",
    "else:\n",
    "    cems_code = [os.path.basename(f.file_name).split(\"_\")[0] for f in dl.dataset.list_of_windows]\n",
    "\n",
    "iou_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_iou,\n",
    "                                                    label_names=[f\"IoU_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "recall_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_recall,\n",
    "                                                       label_names=[f\"Recall_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "join_data_per_code = pd.merge(recall_per_code,iou_per_code,on=\"code\")\n",
    "join_data_per_code = join_data_per_code.set_index(\"code\")\n",
    "join_data_per_code = join_data_per_code*100\n",
    "print(f\"Mean values across flood events: {join_data_per_code.mean(axis=0).to_dict()}\")\n",
    "join_data_per_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-sunrise",
   "metadata": {},
   "source": [
    "### Step 8: Save trained model\n",
    "    - Save model to local/gcs along with configuration file used to conduct training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "muslim-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning.utilities.cloud_io import atomic_save\n",
    "from ml4floods.models.config_setup import save_json\n",
    "\n",
    "# Save in the cloud and in the wandb logger save dir\n",
    "atomic_save(model.state_dict(), f\"{experiment_path}/model.pt\")\n",
    "# Save cofig file in experiment_path\n",
    "config_file_path = f\"{experiment_path}/config.json\"\n",
    "save_json(config, config_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-pocket",
   "metadata": {},
   "source": [
    "#### Optional: Save weights and biases model and finish connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "transparent-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "Run pip install nbformat to save notebook history\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21640<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/gonzalo/ml4floods/notebooks/models/wandb/run-20210318_151018-25j7wene/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/gonzalo/ml4floods/notebooks/models/wandb/run-20210318_151018-25j7wene/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>25660</td></tr><tr><td>_timestamp</td><td>1616105878</td></tr><tr><td>_step</td><td>24583</td></tr><tr><td>loss</td><td>0.87475</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>val_bce_loss</td><td>1.81653</td></tr><tr><td>val_dice_loss</td><td>0.66332</td></tr><tr><td>val_recall land</td><td>0.86352</td></tr><tr><td>val_recall water</td><td>inf</td></tr><tr><td>val_recall cloud</td><td>inf</td></tr><tr><td>val_iou land</td><td>0.78074</td></tr><tr><td>val_iou water</td><td>0.37365</td></tr><tr><td>val_iou cloud</td><td>0.20163</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>_timestamp</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>epoch</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>val_bce_loss</td><td>ââââ</td></tr><tr><td>val_dice_loss</td><td>ââââ</td></tr><tr><td>val_recall land</td><td>ââââ</td></tr><tr><td>val_recall water</td><td></td></tr><tr><td>val_recall cloud</td><td></td></tr><tr><td>val_iou land</td><td>ââââ</td></tr><tr><td>val_iou water</td><td>ââââ</td></tr><tr><td>val_iou cloud</td><td>ââââ</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1728 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">solar-morning-1</strong>: <a href=\"https://wandb.ai/ipl_uv/ml4floods-notebooks_models/runs/25j7wene\" target=\"_blank\">https://wandb.ai/ipl_uv/ml4floods-notebooks_models/runs/25j7wene</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if setup_weights_and_biases:\n",
    "    torch.save(model.state_dict(), os.path.join(wandb_logger.save_dir, 'model.pt'))\n",
    "    wandb.save(os.path.join(wandb_logger.save_dir, 'model.pt')) # Copy weights to weights and biases server\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-subsection",
   "metadata": {},
   "source": [
    "All Done - Now head to the Model Inference Tutorial to see how your model performed!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml4fl_py38]",
   "language": "python",
   "name": "conda-env-ml4fl_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
